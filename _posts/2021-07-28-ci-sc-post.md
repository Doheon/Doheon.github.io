---
title: "[성능비교] Sentence Classification - Doc2Vec, LSTM, KoBERT"
toc: true
toc_sticky: true
date: 2021-07-28
categories: 성능비교 NLP
---

뉴스의 본문을 가지고 뉴스의 8가지의 카테고리를 분류하는 동일한 task를 Doc2Vec, 임베딩 후 LSTM, KoBERT 이렇게 세 가지의 방법으로 진행해 보았다.

&nbsp;



수행한 과정은 아래와 같다.

[Doc2Vec](https://doheon.github.io/code-implementation/nlp/ci-doc2vec-post/)

[FastText + LSTM](https://doheon.github.io/code-implementation/nlp/ci-lstm-post/)

[KoBERT](https://doheon.github.io/code-implementation/nlp/ci-kobert-post/)

&nbsp;



각 모델들의 최종 성능은 아래와 같다.

| Method          | Accuracy |
| --------------- | -------- |
| Doc2Vec         | 81.0%    |
| KoBERT          | 86.8%    |
| FastText + LSTM | 81.8%    |

&nbsp;



test set에 대한 정확도는 KoBERT > LSTM >= Doc2Vec 으로 나왔다.

정확도는 모두 80%대로 정확도만 봤을때는 엄청난 차이가 있는것 같지는 않았다.

하지만 직접 입력한 문장에 대한 결과는 KoBERT가 압도적으로 좋게 느껴졌다. 다른 모델들은 고정된 길이에 대해서 인풋을 받아서 병목현상이 발생하지만 BERT 모델은 attention mask를 통해 다양한 길이에 대해 처리를 할 수 있기 때문이라고 생각된다.

KoBERT를 사용하는 방법이 별도의 토큰화나, 임베딩을 따로 구현하지 않아서 가장 구현하기 쉬웠음에도 불구하고 가장 좋은 성능을 가지고 있었다.

확실히 자연어 처리에서는 BERT와 같은 Transformer기반의 모델의 성능이 기존의 RNN기반의 모델보다 매우 뛰어나다는 것을 느꼈다.

&nbsp;
