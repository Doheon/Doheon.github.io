---
title: "[인공지능 데브코스] 4주차 day2 - AWS"
toc: true
toc_sticky: true
date: 2020-12-22
categories: aws
---

## 12월 22일 화   

아마존 웹 서비스를 이용하여 서버를 호스팅 받아서 머신러닝 API를 배포하는 과정까지 진행해 보았다. 시행착오를 많이 겪었지만  AWS를 사용하는 방법을 익힐 수 있었다.  



## AWS를 활용한 인공지능 모델 배포  
클라우드 환경에서의 인공지능 모델 서빙 API 개발  
<p>&nbsp;</p>  


## 클라우드 기초  

과거에는 인터넷 환경에서 서비스를 제공하기 위해 서비스 제공자는 서비스 호스팅에 필요한 모든 것을 직접 구축  

하지만 서버를 직접 구축하고 운영하는 자원과 인력 비용이 크고 운영 상황의 변화에 능동적으로 대응하기가 어려움  
=> IDC의 등장  

서버임대를 통해 자원을 효율적으로 이용하고 비용을 줄일 수 있었지만  
대부분의 IDC의 서버 임대는 계약을 통해 일정 기간 임대를 하는 유연성이 떨어지는 구조  
<p>&nbsp;</p>  

**Cloud Computing**  
언제 어디서나 필요한 만큼의 컴퓨팅 자원을 필요한 시간만큼 인터넷을 통하여 활용할 수 있는 컴퓨팅 방식  

빅데이터의 수집, 저장, 분석을 위한 방대한 컴퓨팅 자원과 인공지능 개발을 위한 고성능 컴퓨터를 스타트업이나 중소기업이 처음부터 모든 것을 별도로 구입하지 않고도 적은 비용으로 빠르게 필요한 IT환경 마련 가능  
<p>&nbsp;</p>  

**장점**  
속도 (이용할 수 있는), 접근성, 확장성, 생산성, 보안, 안정성, 측정가능성  
<p>&nbsp;</p>  

**클라우드 컴퓨팅 운용 모델**  
클라우드 컴퓨팅은 구축 및 배포 유형에 따라 세가지 형태로 구분  
<p>&nbsp;</p>  

- 프라이빗  
고객이 자체 데이터센터에서 직접 클라우드 서비스를 구축하는 형태

- 하이브리드  
고객의 핵심 시스템은 내부에 두면서도 외부의 클라우드를 활용하는 형태

- 퍼블릭  
서비스 유지를 위한 모든 인프라와 IT기술을 클라우드에서 사용
<p>&nbsp;</p>  


**클라우드 서비스 제공 모델**  
클라우드 서비스 제공 방식에 따라  
IaaS, PaaS, SaaS 세 가지 형태로 구분  

\\<!--![Alt Text](/assets/images/aws/aws1.png)-->

서비스를 구축할때 내가 어디까지 핸들링 해야하는가에 따라 선택적으로 사용  
<p>&nbsp;</p>  

**클라우드 서비스 제공 사업자**  
AWS, GCP, Azure, NCP  
<p>&nbsp;</p>  

**AWS Cloud Computing**  
AWS는 인프라와 기초 서비스 뿐만 아니라 사용자 니즈에 맞는 다양한 어플리케이션 서비스를 제공  
(우리는 EC2사용할 예정)  
<p>&nbsp;</p>  

## 실습: AWS & 실습 환경 세팅

**EC2 생성**  
AMI 선택  
인스턴스 유형 선택 & 보안 그룹 설정  
t5.micro, 계속 다음누르다가 보안그룹에서 새규칙 추가, 포트범위 5000, 소스범위 0.0.0.0/0  
키페어 생성 & 인스턴스 시작  
키페어 생성하고 다운로드, 그 파일이 있어야 접속가능  
인스턴스 생성 확인  
<p>&nbsp;</p>  

**탄력적 IP 설정**  
인스턴스를 중지 또는 종료 후 다시 시작하거나 생성하게 되면 기존 퍼블릭 IP가 변경됨. 퍼블릭 IP를 고정으로 사용하고 싶을 때 탄력적 IP주소를 할당  

네트워크및 보안 -> 탄력적 IP주소 할당  
탄력적 IP주소 연결  


**VS Code로 환경 테스트**  
인스턴스 연결 초기화  
인스턴스에 연결  
터미널  

ssh -i "kdt.pem" ubuntu@ec2-3-34-167-90.ap-northeast-2.compute.amazonaws.com  
ssh -i "~/AI_School/AWStest/kdt.pem" ubuntu@3.34.167.90  
pytorch_p36사용  
<p>&nbsp;</p>  

## API to serve ML model  

Architecture of API to serve ML model  

AWS EC2에서 API 서버를 만드는게 목표  

\\<!--![Alt Text](/assets/images/aws/aws2.png)-->
<p>&nbsp;</p>  


**API란?**
application programming interface의 약자로 기계와 기계, 소프트웨어와 소프트웨어 간의 커뮤니케이션을 위한 인터페이스를 의미  
<p>&nbsp;</p>  

**RESTful API for ML/DL model inference**  
REST 아키텍처를 따르는 API로 HTTP URI를 통해 자원을 명시하고 HTTP Method를 통해 필요한 연산을 요청하고 반환하는 API를 지칭  
특징: 요청 메세지만 봐도 어떤 내용으로 되어 있는지 알 수 있도록 표현됨  
<p>&nbsp;</p>  

Practical process of machine learning  

\\<!--![Alt Text](/assets/images/aws/aws3.png)-->
<p>&nbsp;</p>  

**Model Serving**  
학습된 모델을 REST API방식으로 배포하기 위해서 학습된 모델의 Serialization과 웹 프레임 워크를 통해 배포 준비 필요  

\\<!--![Alt Text](/assets/images/aws/aws4.png)-->
<p>&nbsp;</p>  

**Serialization & De-serialization**  
학습한 모델의 재사용 및 배포를 위해서 저장하고 불러오는 것  
여기에서는 joblib을 사용  

serialization: model object를 disk에 write하여 어디든 전송하고 불러올 수 있는 형태로 변환
모델을 메모리에 올리는 것  

De-Serialization: Python혹은 다른 환경에서 model을 불러와 추론/학습에 사용  
<p>&nbsp;</p>  

**Skeleton of handler to serve model**  
핸들러를 통해 일련의 과정을 한번에 처리  
<p>&nbsp;</p>  

**Model serving을 위한 다양한 Frameworks**  
딥러닝 모델의 안정적인 serving을 위해 TensorFlow serving이나 TorchServe, TensorRT와 같은 프레임 워크를 사용하는 것이 일반적  

flask와 같은 웹 프레임워크는 클라이언트로부터의 요청을 처리하기 위해 주로 사용  
<p>&nbsp;</p>  


## 실습: Serialization & De-serialization

머신러닝 모델 학습  

3.35.192.33  
git clone https://github.com/sackoh/kdt-ai-aws  



serialization  
joblib을 이용하여 진행  


de serialization  
model = joblib.load(‘model/ml_model.pkl’)  

model_input = vectorizer.transform([text])  
model_output = model.predict_proba(model_input)  

앞에서 모델을 학습했던 방식 그대로 모델을 불러와야하고 전처리 했던 방식 그대로 처리해 줘야 한다.  

joblib으로 하면 joblib으로 해야한다.  
<p>&nbsp;</p>  


## inference를 위한 model handler개발

**Define Inference**  
```python
class ModelHandler(BaseHandler):
	def __init__(self):
		pass
	
	def initalize(self, **kwargs):
		pass
		
	def preprocess(self, data):
		pass
		
	def inference(self, data):
		pass
		
	def postprocess(self, data):
		pass
	
	def handle(self, data):
		pass
```

**handle()**  
요청 정보를 받아 적절한 응답을 반환  
1. 정의된 양식으로 데이터가 입력됐는지 확인
2. 입력 값에 대한 전처리 및 모델에 입력하기 위한 형태로 변환
3. 모델 추론
4. 모델 반환값의 후처리 작업
5. 결과 반환
<p>&nbsp;</p>  

**note**  
모델은 보통 전역변수로 불러온다.  
일반적으로 요청을 처리하기 전에 모델을 불러온다.  
<p>&nbsp;</p>  

**initialize()**  
데이터 처리나 모델, configuration등 초기화  
신경망을 구성하고 초기화  
사전 학습한 모델이나 전처리기 불러오기  
<p>&nbsp;</p>  

**preprocess()**  
Raw input을 전처리 및 모델 입력가능한 형태로 변환  
<p>&nbsp;</p>  


**inferenct()**  
입력된 값에 대한 예측/추론  
<p>&nbsp;</p>  

**postprocess()**  
모델의 예측값을 response에 맞게 후처리 작업  
<p>&nbsp;</p>  

```python
from model import MLModelHandler
mlhandler = MLModelHandler()
text = []
result = mlhandler.handle(text)
```
<p>&nbsp;</p>  


## Flask 기반 감성분석 API 개발  

key: value 형태의  json포맷으로 요청을 받아 text index별로 key:value로 결과를 저장한 json포맷으로 결과 반환  


**터미널에서 하는법**  
```
curl -d'{"text": ["재밌당!", "재미없어!"], "use_fast": false}' \
-H "Content-Type: application/json" \
-X POST\
http://host:port/predict
```
<p>&nbsp;</p>  


**파이썬에서 하는법**  

```python
import requests
url = 'http://host:port/predict'
data = {"text": ["재밌당!", "재미없어!"], "use_fast":False}
response = requests.post(url, json = data)
print(response.content)
```
<p>&nbsp;</p>  