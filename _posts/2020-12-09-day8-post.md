---
title: "[인공지능 데브코스] 2주차 day3 - 직교행렬, SVD, 벡터공간, 통계학 기본개념"
toc: true
toc_sticky: true
date: 2020-12-09
categories: TIL 수학
use_math: true
---

## 12월 09일 수   

오늘은 선형대수학을 끝마치고 통계학의 기본개념에 대해서 공부했다.  
선형대수학을 삼일만에 완벽하게 습득하는 하는 것은 불가능하지만 그래도 복습겸 개념을 정리하는 데에 큰 도움이 된 것 같다.  
인공지능을 하기 위해서는 선형대수학 뿐만 아니라 통계학 또한 매우 중요하다고 들었는데통계학도 확실하게 정리하고 넘어가서 인공지능을 할때 어려움이 없도록 해야겠다.  
대학교때 아무생각 없이 통계학 수업을 들었던 적이 있는데 공부하는데 조금 도움이 되는 것 같다. 

## 직교행렬  

### 투영 (projection)  
두 벡터 $u, a$가 있을때, 벡터 $u$를 $a$위에 투영한 벡터를 $proj_au$라 하고 다음과 같이 구한다.  

<center> $proj_au = \left(\frac{u \cdot a}{||a||}\right) \left(\frac{a}{||a||}\right) = \left(\frac{u \cdot a}{||a||^2}\right) a$</center>  

벡터 $u$를 $a$위에 투영하고 남은 보완 벡터는 $u-proj_au$이다.  
두 벡터 $u, a$ 가 있을 때, 투영과 보완의 개념을 이용해 직교분할 할 수 있다.  

### 직교행렬 (Orthogonal Matrix)  
  

**행렬은 각 열벡터가 basis를 이루는 좌표계이다.**  
- 직교행렬(orthogonal matrix) : 주어진 행렬의 모든 열벡터가 직교한다면, 이 행렬을 직교행렬이라고 한다. 직교행렬은 직교좌표계를 의미한다.  
- 정규직교행렬(orthonormal matrix): 주어진 행렬이 직교행렬이고 모든 열벡터의 크기가 1이라면 이 행렬을 정규직교행렬이라고 한다. 정규직교행렬은 정규직교좌표계를 의미한다. 
<p>&nbsp;</p>  

**직교행렬을 이용한 선형시스템**  
선형시스템 $Ax = b$에서 행렬 $A$가 직교행렬(orthogonal matrix)이면, 해(solution) $x$ 는 역행렬 $A^{-1}$의 계산없이 다음과 같이 구할 수 있다.  
- $x$의 $i$번째 요소는 투영으로 계산할 수 있다. 벡터 $b$를 행렬 $A$의 각열벡터 $a_i$에 투영한 값이 $x_i$가 된다. 만약 $A$가 정규직교행렬이라면 $x_i$의 값은 $b$와 $a_i$의 내적의 결과이다.($x_i = b \cdot a_i$)  
- $x$의 $i$번째 요소와 $j$번째 요소의 계산은 독립적이다. 즉 $x$의 계산은 병렬처리 가능하다.  
<p>&nbsp;</p>  


### QR분해 (QR Decomposition)  

주어진 행렬에서 정규직교행렬을 추출하는 분해법  
QR분해는 주어진 행렬을 특정한 형태를 가지는 두 행렬의 곱으로 나누는 행렬분해이다.  
$\quad A = QR$  
- Q: orthonormal matrix(정규직교행렬)
- R: upper triangular matrix(상삼각행렬)
<p>&nbsp;</p>  

**주어진 행렬 A가 QR분해 되어있을때 장점**  
- $Ax = b \quad \Rightarrow \quad (QR)x = b \quad \Rightarrow \quad Q(Rx) = b \quad \Rightarrow \quad Qy = b, Rx = y$  
내적을 이용하여 y를 구하고 back-substitution을 이용하여 x를 구한다.  
LU분해와 마찬가지로 어려운 한가지 문제를 쉬운 두가지 문제로 변환한다.  

**QR분해는 그람-슈미트 과정(Gram-Schmidt process) 을 행렬로 코드화 한 것이다.**  
- Q: 행렬 A에서 정규직교성을 추철한 행렬
- R: 행렬 A에서 정규직고성 추출 후 남은 행렬(상삼각행렬로 남는다)
<p>&nbsp;</p>  

**QR decomposition의 활용**  
- 빠른 계산: 선형시스템 Ax=b의 해를 구할 때 빠르게 구할 수 있다.
(Q를 풀때 병렬처리, R을 풀때는 그냥 처리)  
<p>&nbsp;</p>  

**QR 분해 vs LU 분해**  
- LU분해의 경우, 선형시스템을 풀 때 병렬처리 할 수 없다.
- QR분해의 경우, Q행렬이 꽉찬 구조를 가진 행렬이므로 메모라 사용량이 많다.  
<p>&nbsp;</p>  


## SVD (Singular Value Decomposition)  

$A_{m \times n} = U_{m \times m} * D_{m \times n} * V^T_{n \times n}$  

행렬 $U, D, T$는 그 특성에 따라 다음과 같은 의미가 있다.  
- $U$: m차원 회전행렬 (정규직교행렬)  
- $D$: n차원 확대축소 (대각선만 값이 있음)  
- $V$: n차원 회정행렬 (정규직교행렬)  

=> 특이값 분해는 행렬을 회전과 확대축소로 분해하는 방법이다.  


**주성분분석(Principa Component Analysis, PCA)**  
다수의 n차원 데이터에 대해, 데이터의 중심으로부터 데이터의 응집력이 좋은 n개의 직교 방향을 분석하는 방법  
데이터의 공분산행렬에 대한 고유값분해에 기반을 둔 직교분해  

D값으로 주성분이 무엇인지 알 수 있다.  
demension reduction할 때 사용가능  


## 벡터공간과 최소제곱법  

### 집합
집합은 임의의 원소를 수집하여 만든 모듬  

**집합이 연산에 닫혀있다.**  
어떤 연산을 생각한 다음 집합에서 임의의 원소를 뽑아 연산을 수행한 결과가 여전히 집합의 원소로 있다면, 해당집합은 연산에 닫혀있다고 한다.  
ex) 실수집합은 덧셈과 곱셈에 대해 닫혀있다.  

### 공간  

공간은 다음의 두 연산에 닫혀 있는 집합이다.  
- 덧셈연산: 집합에서 임의의 두 원소 x, y를 뽑아 더해도 그 결과는 집합의 원소이다.
- 스칼라 곱: 집합에서 임의의 한 원소 x를 뽑아 임의의 스칼라배 한 결과는 집합의 원소이다.
모든 n-벡터 집합 $R^n$은 n차원 벡터 공간(vector space)라 부를 수 있다.  


### 열공간(column space)  

행렬 A의 열벡터들에 대한 가능한 모든 선형조합의 결과를 모아 집합으로 구성할 때 이 집합을 column space(열공간)이라 하고 $col(A)$라고 표기한다.  
선형시스템 $Ax = b$가 해를 가지면(consistent) $b$ 는 $col(A)$에 원소이다.  ($b \in col(A)$)  
선형시스템 $Ax = b$가 해를 가지지 않으면(inconsistent) $b$는 $col(A)$에 속하지 않는다. ($b \not\in col(A)$)  

**선형시스템 $Ax = b$에 대한 해가 없음에도 불구하고 할 수 있는 최선은 무엇일까?**   
행렬 $A$가 정의하는 열공간에서 우리의 목표 $b$와 가장 가까운 지점은 $b$를 열공간에 투영시킨 지점일 것이다. 즉, 최선의 목표를 $proj_wb$라고 할 수 있다.


### 최소제곱법(least squares method)  
최소제곱법은 선형시스템 $Ax = b$에 대한 해 $x$가 없음에도 불구하고 최선의 대안을 구하는 방법이다.  
이 방법은 목표 $b$와 달성가능한 목표 $\bar{b}$의 차이의 제곱길이를 최소화 시키는 의미를 가지기 때문에 최소 제곱법이라 불린다.  

주어진 선형시스템의 양변에 전치행렬을 곱하면 최소제곱법의 해를 구할 수 있다.  

$\quad\; Ax = b$  
$\Rightarrow A^TA\bar{x} = A^Tb$  
$\Rightarrow (A^TA)^{-1}A^Tb$  

$A^TA$는 역행렬을 가지며 해를 구할 수 있다.  
$\bar{x}$는 실제 해가 아닌 근사해(approximate solution)이다.  


### 최소제곱법의 응용  

**선형회귀(Linear Regression)**  
선형회귀 문제는 다음과 같이 최소제곱법으로 풀 수 있다.  

1. 직선이 각 정점을 모두 지나간다고 가정하고 선형시스템 $Ax = b$구성
2. y = mx + b를 가설로 설정하고 행렬식을 구성
3. 양변에 AT곱한 후 선형시스템을 해결  
<p>&nbsp;</p>  


## 통계학의 기본개념  

**통계학(statistics)**  
- 데이터의 수집(collection), 구성(organization), 분석(analysis), 해석 (interpretation), 표현(presentation)에 관한 학문
- 기술통계학 (descriptive statistics) (기술하라 할때 기술)
- 추측통계학 (inferential statistics)


### 용어정리  

**모집단 (population)**  
어떤 질문이나 실험을 위해 관심의 대상이 되는 개체나 사건의 집합  
ex) 전교 남학생의 키  
<p>&nbsp;</p>  

**모수(parameter)**  
모집단의 수치적인 특성  
ex) 키의 평균  
<p>&nbsp;</p>  

**표본 (sample)**  
모집단에서 선택된 개체나 사건의 집합  
<p>&nbsp;</p>  

**도수 (frequency)**  
정의: 어떤 사건이 실험이나 관찰로부터 발생한 횟수  
표현 방법  
- 도수분포표 (Frequency Distribution Table)
- 막대그래프 (Bar graph)
- 히스토그램 (Histogram)
히스토그램은 연속적으로 자료를 표현한다는게 막대그래프랑 다르다  
- 줄기-잎 그림  
<p>&nbsp;</p>  


**상대도수 (relative frequency)**  
도수를 전체 원소의 수로 나눈것  
<p>&nbsp;</p>  

**평균(mean)**
- 모평균 $\mu$: 모집단 전체 일 경우
- 표본평균 $\bar{x}$: 모집단에서 추출한 표본일 경우
<p>&nbsp;</p>  

**중앙값(Median)**  
평균의 경우 극단 값의 영향을 많이 받음  
자료를 순서대로 나열했을 때 가운데 있는 값  

자료의 수가 n일때  
- n이 홀수: (n+2)/2 번째 자료값
- n이 짝수:  n/2번째 와 n/2 + 1 번빼 자료값의 평균  
<p>&nbsp;</p>  


**분산(Variance)**  
편차의 제곱의 합을 자료의 수로 나눈값  
편차: 값과 평균의 차이  

- 모분산: 자료가 모집단일때   
$\sigma^2 = {1 \above 1pt N} \sum_{i=1}^N (x_i - \mu)^2$  

- 표본분산: 자료가 표본집단일때  
$s^2 = {1 \above 1pt n-1} \sum_{i=1}^n (x_i - \bar {x})^2$  

표본분산을 구할 때는 (n-1)로 나누는 것에 주의한다.
(표본분산의 기댓값이 모분산과 같아지기 위해 이렇게 한다)  
<p>&nbsp;</p>  


**표준편차 (Standard Deviation)**  
- 분산의 양의 제곱근
- 모표준편차 (population standard deviation)  
$\sigma = \sqrt{ {1 \above 1pt N} \sum_{i=1}^N (x_i - \mu)^2 }$  
- 표본표준편차 (sample standard deviation)  
$s = \sqrt{ {1 \above 1pt n-1} \sum_{i=1}^n (x_i - \bar {x})^2 }$  
<p>&nbsp;</p>  

**범위(Range)**  
자료를 정렬하였을 때 가장 큰 값과 가장 작은 값의 차이  
<p>&nbsp;</p>  

**사분위수 (Quartile)**  
전체 자료를 정렬했을 때 $\frac{1}{4}, \frac{2}{4}, \frac{3}{4}$위치에 있는 숫자  
Q1 = 제 1 사분위수  
Q2 = median  
Q3 = 제 3 사분위수  
<p>&nbsp;</p>  

**z-score**  
어떤 값이 평균으로부터 몇 표준편차 떨어져 있는지를 의미하는 값
- 모집단의 경우  
$z = \frac{x - \mu}{\sigma}$  

- 표본의 경우  
$z = \frac{x - \bar{x}}{s}$  
