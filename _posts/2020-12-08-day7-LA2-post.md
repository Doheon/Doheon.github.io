---
title: "[인공지능 데브코스] 2주차 day2 - LU분해, 선형조합, 좌표계, 선형변환"
toc: true
toc_sticky: true
date: 2020-12-08
use_math: true
---

## 12월 08일 화  

어제에 이어서 인공지능에 필요한 선형대수학을 공부했다. 
옛날에 배웠던 내용들이 점점 기억나고 있는 것 같다. 
중요한 개념들을 되짚어 보면서 여러가지 개념들에 대해 확실하게 이해하고 넘어갈 수 있었다.  



## 행렬  

### 행렬분해  
주어진 행렬을 행렬분해 한 상태로 가지고 있으면 계산이 편한 경우가 많다.  
행렬분해의 예  
- LU 분해
- QR 분해
- 특이값 분해 (SVD)  
<p>&nbsp;</p>  

### LU 분해 (LU Decomposition)  
가우스 소거법을 행렬의 형태로 적용한것  

$A = L * U$  

$L$ : lower triangular matrix (하삼각행렬)  
$U$ : upper triangular matrix (상삼각행렬)  

주어진 행렬 $A$ 가 LU 분해 되었을 때 장점  
- $Ax = b \quad \Rightarrow \quad (LU)x = b \quad \Rightarrow \quad L(Ux) = b \quad \Rightarrow \quad Ly = b, y = Ux$  

=> y를 구하고 x를 구한다.  
위와같이 어려운 문제를 쉬운 두 가지의 문제로 분해하여 해결 할 수 있다.  

**LU 분해는 가우스 소거법의 forward elimination을 행렬로 코드화 한 것!**  

$L$: 행렬 $A$를 전방소거 하는데 쓰인 replacement 와 scaling에 대한 행렬  
$U$: 행렬 A를 전방소거 후 남은 upper triangular matrix  
$P$: 행렬 A를 전방소거하는데 쓰인 interchange에 대한 행렬  
=> 실제로는 $PLU$로 표현이 된다.  
**가우스 소거법의 forward elimination과 의미가 같다!**

**LU분해가 사용되는 이유**
- 수치적 안정성: 선형시스템 $Ax = b$의 해를 $A^{-1}$을 이용해 직접 구하는 것 보다 $PLU$분해를 이용하는 것이 좀 더 수치적으로 안정적이다.
- $b$가 자주 업데이트 되는 경우: 선형시스템 $Ax = b$에서 $A$는 고정되어있고 $b$가 자주 변하는 문제에서 $A$를 미리 $PLU$분해해 둔다면 $x$를 실시간으로 구할 수 있다. (역핼렬보다 연산이 더 빠르다)  
<p>&nbsp;</p>  

### 행렬 (matrix)  

#### 용어정리  
- $m \times n$ 행렬: 행의 개수가 m, 열의 개수가 n인 행렬  
- $a_{ij}$: i행 j열의 값  
- 전치행렬 (transpose matrix): 행과 열을 바꾼 행렬  
- 벡터: 보통 열벡터를 의미하며 소문자로 표기  
- 영행렬(zero matrices): 행렬의 모든 요소가 0인 행렬  
- 행렬의 합: 행과 열의 개수가 모두 같을때만 성립, 각요소의 합  
- 정방행렬(square matrix): 행과 열의 개수가 모두 n인 정사각형 모양의 행렬을 n차 정방행렬 이라고 한다.  
- 특히 $a_{ii}$를 행렬의 main diagonal(주대각선)이라고 한다. 
- 항등행렬(identity matrices): 주대각선이 1이고 나머지 요소는 모두 0인 n차 정방행렬을 항등행렬 이라 한다.  
행렬곱에 대한 항등원 역할을 한다.  
- 행렬의 곱  
두 행렬의 곱의 결과행렬의 $a_{ij}$의 값은 처음 나오는 행렬의 i번째 행벡터와 나중에 나오는 행렬의 j번째 열벡터를 내적한 결과이다.
=> $(m \times r) * (r \times n) = (m \times n)$  
행렬의 곱은 병렬처리(parallel processing)로 가속할 수 있다.  

#### 텐서 (tensor)
텐서(tensor)는 스칼라, 벡터, 행렬을 아우르는 개념이다. 숫자가 늘어설 수 있는 방향이 k개면 k-텐서로 부른다.  
늘어설 수 있는 방향을 축이라고 생각하면 차원이라고 생각하면 된다.
- 0-텐서: 스칼라(점)  
- 1-텐서: 벡터(선)  
- 2-텐서: 행렬(면)  
- 3-텐서: 3차원 행렬 (부피)  

n-tensor까지 모두 만들 수 있다.  


#### 분할행렬 (Partitioned Matrix)  
추상적 구조로 행렬을 취급하고 행렬연산을 하는 것  
행렬을 조각 단위로 분할하여 생각해도 무방하다.  
이런 관점에서 본다면 행렬은 부분행렬(submatrix) 로 이루어진 직사각형 구조로 확장해서 생각할 수 있다.  
이렇게 행렬을 구조적으로 보는 방법을 분할행렬 또는 블록행렬(block matrix)라고 한다.  

- $3 \times 3$ 행렬을 row vector로 이루어져 있는 $3 \times 1$ 행렬로 표현가능하고 column vector 로 이루어져 있는 $1 \times 3$ 행렬로도 표현이 가능하다.  

<center> $\begin{bmatrix} a_{11} & a_{12} & a_{13} \cr a_{21} & a_{22} & a_{23} \cr a_{31} & a_{32} & a_{33} \end{bmatrix} = \begin{bmatrix} r_1\cr r_2\cr r_3 \end{bmatrix} = \begin{bmatrix} c_1 & c_2 & c_3 \end{bmatrix} $</center>  
<p>&nbsp;</p>  

- 두 행렬의 곱 $AB = C$를 아래와 같이 matrix-column vector prodects로 볼 수 있다.  

<center> $AB = \begin{bmatrix} Ab_1 & Ab_2 & ... & Ab_n \end{bmatrix} = C$ </center>   
 <p>&nbsp;</p>  

- 두 행렬의 곱 $AB = C$를 아래와 같이 row vector-matix products로도 볼 수 있다.  

<center> $AB = \begin{bmatrix} {a_1}B \cr {a_2}B \cr ... \cr {a_n}B \end{bmatrix} = C$ </center>  
<p>&nbsp;</p>  



## 선형조합 (Linear Combination)  
$Ax$는 $A$의 열벡터에 대한 선형조합이다.  

행렬을 구조적으로 바라보는 법  
=> 행렬은 열벡터의 리스트다! $m \times n$ 행렬은 m-벡터가 n개 있다고 생각하면 된다.  

$Ax$는 행렬 $A$가 가지고 있는 열벡터의 선형 조합이다.  
$Ax = x_1a_1 + x_2a_2 + ... + x_na_n$  

선형대수에서는 이처럼 벡터들의 대한 가중치 합을 특히 선형조합 (Linear Combination)이라 부른다.  
=>$Ax$의 결과는 행렬 $A$가 가지고 있는 열벡터의 선형조합으로만 한계가 지어진다. (weighted sum, $Ax$는 복잡해지는데에 한계가 있다.)  

행렬 A의 열벡터들에 대한 가능한 모든 선형조합의 결과를 모아 집합으로 구성할 수 있을 것이다. 이 집합을 column space(열공간)이라 하고 $col(A)$와 같이 표기한다.  


## 좌표계 (Coordinate System)  

2- 벡터v는 원점에서 시작해서 (a,b)로끝나는 벡터를 의미한다.  

<center> $ v = \begin{bmatrix} {a} \cr {b} \end{bmatrix} = \begin{bmatrix} 1 & 0 \cr 0 & 1 \end{bmatrix} \begin{bmatrix} {a} \cr {b} \end{bmatrix} = a\begin{bmatrix} {1} \cr {0} \end{bmatrix} + b\begin{bmatrix} {0} \cr {1} \end{bmatrix} $ </center>  

x축으로 a만큼, y축으로 b만큼 움직였다고 해석할 수 있으며 여기에 사용된 항등행렬이 이 연산의 좌표계이며 xy-좌표계라고 부른다.
항등행렬이 아니더라도 다양한 좌표계를 설정할 수 있으며 각 열벡터의 선형조합의 결과가 나온다. 

### 좌표계 변환 (Change of Basis)  
역행렬을 이용해 선형시스템의 해를 구하는 문제를 좌표계 변환으로 바라볼수 있다.  
선형시스템 문제를 좌표계 변환이라고도 생각할 수 있다.  

$Ax = b$  
우항: 표준좌표계 에서 어떤 벡터의 좌표값은 b이다  
좌항: $A$의 열벡터들을 기저로 가지는 좌표계에서는 동일 벡터의 좌표값은 x이다. 

$x = A^{-1}b$  
좌항: 표준 좌표계에서 어떤 벡터의 좌표값은 x이다
우항: A-1의 열벡터들을 기저로 가지는 좌표계에서는 동일 벡터의 좌표값은 b이다. 

=> 행렬은 **좌표계** 이고, 벡터는 **좌표값** 이다.  
임의의 v는 다양한 좌표계에서 표현될 수 있다.  

## 선형변환 (Linear Transformation)  

### 선형함수(Linear Function)  
만일 함수 f가 아래 두가지 조건을 만족하면 함수 f를 선형함수 (linear function)이라고 한다.  
- $f(x+y) = f(x) + f(y)$  
- $f(cx) = cf(x)$  
(단, c는 임의의 스칼라)  

- 임의의 두 입력에 대해 + 연산을 먼저 수행한 결과를 함수 입력으로 넣고 함수를 수행한 결과와 각 입력에 대해 함수를 수행한 후 나온 결과에 대해 +연산을 수행한 결과는 같다.
- 임의의 입력에 대해 스칼라 곱셈 연산을 먼저 수행한 다음 함수를 수행한 겨로가와 입력에 대해 함수를 수행한 후 나온 결과에 대해 스칼라 곱셈 연산을 수행한 결과는 같다.


### 선형변환(Linear Transformation)  

**변환(Transformation)**  
함수의 입력이 n-벡터이고 출력이 m-벡터인 함수를 변환(tranformation)이라고 한다.  
$ T: R^n \to R^m $

특별히 **n=m** 인 경우, 해당 변환을 연산자(operator)라고 한다.  

**행렬은 선형변환일까?**  
$A(x+y) = Ax + Ay$  
$A(cx) = cAx$  
=>모두 만족. 행렬은 선형변환이다.  

=> $m \times n$ 행렬은 n-벡터를 입력으로 받아 m-벡터를 출력으로 내는 선형변환이며 임의의 선형변환은 행렬로 표현 가능하다. 즉, 행렬은 선형변환의 구현체 이다. (모든 선형변환은 행렬로 표현가능!)  


### 표준행렬(standard matrix)

**선형변환 코딩하기**  
다음 절차를 통해 우리가 원하는 방식대로 동작하는 행렬변환을 코딩 할 수 있다.  

1. 구현하고자 하는 기능의 입력과 출력이 벡터로 정의되는지 확인한다.
2. 구현하고자 하는 기능이 선형인지 확인한다.
3. 입력이 n-벡터이고, 출력이 m-벡터이면 $m \times n$ 표준행렬을 구성한다.


**표준행렬 구하기**  
- n차원 표준 기저벡터를 생각 한다.  
- 각 표준기저벡터에 우리가 원하는 기능을 적용시간 결과를 각 열에 적는다.

<center> $ \begin{bmatrix} a & b \cr c & d \end{bmatrix} \begin{bmatrix} 1 \cr 0 \end{bmatrix} = \begin{bmatrix} a \cr c \end{bmatrix}$ </center>  
<p>&nbsp;</p>  

=>기저벡터를 변환하면 구하려는 행렬의 열벡터가 나온다.





