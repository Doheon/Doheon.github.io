---
title: "[인공지능 데브코스] 2주차 day2 - LU분해, 선형조합, 좌표계, 선형변환"
toc: true
toc_sticky: true
date: 2020-12-08
categories: TIL 수학
use_math: true
---

## 12월 08일 화  

어제에 이어서 인공지능에 필요한 선형대수학을 공부했다.  
옛날에 배웠던 내용들이 점점 기억나고 있는 것 같다.  
중요한 개념들을 되짚어 보면서 여러가지 개념들에 대해 확실하게 이해하고 넘어갈 수 있었다.  



## 행렬  

### 행렬분해  
주어진 행렬을 행렬분해 한 상태로 가지고 있으면 계산이 편한 경우가 많다.  
행렬분해의 예  
- LU 분해
- QR 분해
- 특이값 분해 (SVD)  
<p>&nbsp;</p>  

### LU 분해 (LU Decomposition)  
가우스 소거법을 행렬의 형태로 적용한것  

$A = L * U$  

$L$ : lower triangular matrix (하삼각행렬)  
$U$ : upper triangular matrix (상삼각행렬)  

주어진 행렬 $A$ 가 LU 분해 되었을 때 장점  
1. $Ax = b$  
2. $(LU)x = b$  
3. $L(Ux) = b$  
4. $Ly = b, y = Ux$  

=> y를 구하고 x를 구한다.  
위와같이 어려운 문제를 쉬운 두 가지의 문제로 분해하여 해결 할 수 있다.  

**LU 분해는 가우스 소거법의 forward elimination을 행렬로 코드화 한 것!**  

$L$: 행렬 $A$를 전방소거 하는데 쓰인 replacement 와 scaling에 대한 행렬  
$U$: 행렬 A를 전방소거 후 남은 upper triangular matrix  
$P$: 행렬 A를 전방소거하는데 쓰인 interchange에 대한 행렬  
=> 실제로는 $PLU$로 표현이 된다.  
**가우스 소거법의 forward elimination과 의미가 같다!**

**LU분해가 사용되는 이유**
- 수치적 안정성: 선형시스템 $Ax = b$의 해를 $A^{-1}$을 이용해 직접 구하는 것 보다 $PLU$분해를 이용하는 것이 좀 더 수치적으로 안정적이다.
- $b$가 자주 업데이트 되는 경우: 선형시스템 $Ax = b$에서 $A$는 고정되어있고 $b$가 자주 변하는 문제에서 $A$를 미리 $PLU$분해해 둔다면 $x$를 실시간으로 구할 수 있다. (역핼렬보다 연산이 더 빠르다)  
<p>&nbsp;</p>  

### 행렬 (matrix)  

#### 용어정리  
- $m \times n$ 행렬: 행의 개수가 m, 열의 개수가 n인 행렬  
- $a_{ij}$: i행 j열의 값  
- 전치행렬 (transpose matrix): 행과 열을 바꾼 행렬  
- 벡터: 보통 열벡터를 의미하며 소문자로 표기  
- 영행렬(zero matrices): 행렬의 모든 요소가 0인 행렬  
- 행렬의 합: 행과 열의 개수가 모두 같을때만 성립, 각요소의 합  
- 정방행렬(square matrix): 행과 열의 개수가 모두 n인 정사각형 모양의 행렬을 n차 정방행렬 이라고 한다.  
- 특히 $a_{ii}$를 행렬의 main diagonal(주대각선)이라고 한다. 
- 항등행렬(identity matrices): 주대각선이 1이고 나머지 요소는 모두 0인 n차 정방행렬을 항등행렬 이라 한다.  
행렬곱에 대한 항등원 역할을 한다.  
- 행렬의 곱  
두 행렬의 곱의 결과행렬의 $a_{ij}$의 값은 처음 나오는 행렬의 i번째 행벡터와 나중에 나오는 행렬의 j번째 열벡터를 내적한 결과이다.
=> $(m \times r) * (r \times n) = (m \times n)$  
행렬의 곱은 병렬처리(parallel processing)로 가속할 수 있다.  

#### 텐서 (tensor)
텐서(tensor)는 스칼라, 벡터, 행렬을 아우르는 개념이다. 숫자가 늘어설 수 있는 방향이 k개면 k-텐서로 부른다.  
늘어설 수 있는 방향을 축이라고 생각하면 차원이라고 생각하면 된다.
- 0-텐서: 스칼라(점)  
- 1-텐서: 벡터(선)  
- 2-텐서: 행렬(면)  
- 3-텐서: 3차원 행렬 (부피)  

n-tensor까지 모두 만들 수 있다.  


#### 분할행렬 (Partitioned Matrix)  
추상적 구조로 행렬을 취급하고 행렬연산을 하는 것  
행렬을 조각 단위로 분할하여 생각해도 무방하다.  
이런 관점에서 본다면 행렬은 부분행렬(submatrix) 로 이루어진 직사각형 구조로 확장해서 생각할 수 있다.  
이렇게 행렬을 구조적으로 보는 방법을 분할행렬 또는 블록행렬(block matrix)라고 한다.  

- $3 \times 3$ 행렬을 row vector로 이루어져 있는 $3 \times 1$ 행렬로 표현가능하고 column vector 로 이루어져 있는 $1 \times 3$ 행렬로도 표현이 가능하다.  

<center> $\begin{bmatrix} a_{11} & a_{12} & a_{13} \cr a_{21} & a_{22} & a_{23} \cr a_{31} & a_{32} & a_{33} \end{bmatrix} = \begin{bmatrix} r_1\cr r_2\cr r_3 \end{bmatrix} = \begin{bmatrix} c_1 & c_2 & c_3 \end{bmatrix} $</center>  
<p>&nbsp;</p>  

- 두 행렬의 곱 $AB = C$를 아래와 같이 matrix-column vector prodects로 볼 수 있다.  

<center> $AB = \begin{bmatrix} Ab_1 & Ab_2 & ... & Ab_n \end{bmatrix} = C$ </center>   
 <p>&nbsp;</p>  
 
- 두 행렬의 곱 $AB = C$를 아래와 같이 row vector-matix products로도 볼 수 있다.  

<center> $AB = \begin{bmatrix} {a_1}B \cr {a_2}B \cr ... \cr {a_n}B \end{bmatrix} = C$ </center>  
<p>&nbsp;</p>  



## 선형조합 (Linear Combination)  
$Ax$는 $A$의 열벡터에 대한 선형조합이다.

행렬을 구조적으로 바라보는 법
=> 행렬은 열벡터의 리스트다! $m \times n$ 행렬은 m-벡터가 n개 있다고 생각하면 된다.  

$Ax$는 행렬 $A$가 가지고 있는 열벡터의 선형 조합이다.
$Ax = x_1a_1 + x_2a_2 + ... + x_na_n$

선형대수에서는 이처럼 벡터들의 대한 가중치 합을 특히 선형조합 (Linear Combination)이라 부른다.  
=>$Ax$의 결과는 행렬 $A$가 가지고 있는 열벡터의 선형조합으로만 한계가 지어진다. (weighted sum, $Ax$는 복잡해지는데에 한계가 있다.)  

행렬 A의 열벡터들에 대한 가능한 모든 선형조합의 결과를 모아 집합으로 구성할 수 있을 것이다. 이 집합을 column space(열공간)이라 하고 $col(A)$와 같이 표기한다.  


## 좌표계 (Coordinate System)  

2- 벡터v는 원점에서 시작해서 (a,b)로끝나는 벡터를 의미한다.  

<center> $v = \begin{bmatrix} {a} \cr {b} \end{bmatrix} = \begin{bmatrix} 1 & 0 \cr 0 & 1 \end{bmatrix} \begin{bmatrix} {a} \cr {b} \end{bmatrix} = a\begin{bmatrix} {1} \cr {0} \end{bmatrix} + b\begin{bmatrix} {0} \cr {1} \end{bmatrix}</center>  

x축으로 a만큼, y축으로 b만큼 움직였다고 해석할 수 있으며 여기에 사용된 항등행렬이 이 연산의 좌표계이며 xy-좌표계라고 부른다.
항등행렬이 아니더라도 다양한 좌표계를 설정할 수 있으며 각 열벡터의 선형조합의 결과가 나온다. 

### 좌표계 변환 (Change of Basis)  
역행렬을 이용해 선형시스템의 해를 구하는 문제를 좌표계 변환으로 바라볼수 있다.  
 











