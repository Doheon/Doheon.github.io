---
title: "[인공지능 데브코스] 2주차 day4 - 확률, 확률분포"
toc: true
toc_sticky: true
date: 2020-12-10
categories: TIL 수학
use_math: true
---

## 12월 10일 목   

오늘은 통계학의 확률과 확률분포에 대해서 공부했다.  
대학교때 통계학 수업을 들어본적이 있어서 그런지 한번씩 들어봤거나 익숙한 내용들이었다.  
역시 공부를 한번 해놓으면 언젠가는 쓸모가 있는 것 같다.  
이번에 확실하게 공부해서 완전히 내것으로 만들고 넘어가야겠다.  


## 확률 (probability)

### 확률의 정의   

똑같은 실험을 무수히 많이 반복할 때 어떤 일이 일어나는 비율  
=> 상대도수의 극한  

**고전적 정의**  
- 표본공간 (sample space)
모든 가능한 실험결과들의 집합
- 사건
관심있는 실험결과들의 집합  
표본공간의 부분집합  
- 어떤 건이 일어날 확률
표본공간의 모든 원소가 일어날 확률이 같을경우  
=> (사건의 원소의 수)/(표본공간의 원소의 수)  
<p>&nbsp;</p>  

**확률**  
사건 A가 일어날 확률은 보통 P(A)라고 표현한다.  
- 확률 1: 반드시 그 사건이 일어남
- 확률 0: 그 사건이 절대로 일어나지 않음
- 확률은 0에서 1사이의 값을 가짐
<p>&nbsp;</p>  

**고전적 확률**  
- 표본 공간의 원소의 수를 세야함
- 사건의 원소의 수를 세야함
- 따라서 경우의 수를 쉽게 셀 수 있는 방법이 필요
- 조합 (combination) 사용
<p>&nbsp;</p>  

### 확률의 특성  

**조합**  
- 어떤 집합에서 순서에 상관없이 뽑은 원소의 집합
- n개중 r개를 뽑는 조합의 수
${}_n \mathrm{C}_r = \begin{pmatrix} n \cr r \end{pmatrix} = \dfrac{n!}{r!(n-r)!}$  
$n! = n(n-1)(n-2)\ ...\ 2 \cdot1$  
<p>&nbsp;</p>  

**덧셈법칙 (Addition Law)**  
사건 A, B가 있을 때 A 혹은 B가 일어날 확률은 아래와 같다.  
$P(A \cup B) = P(A) + P(B) - P(A \cap B)$  
<p>&nbsp;</p>  

**배반 (Exclusive)**  
두 사건의 교집합이 공집합일 경우 두 사건이 서로 배반이라고 한다. 
$P(A \cap B) = 0$  
$P(A \cup B) = P(A) + P(B)$  
<p>&nbsp;</p>  

**조건부 확률 (Conditional Probability)**  
어떤 사건 A가 일어났을 때, 다른사건 B가 일어날 확률  
$P(B|A) = \dfrac{P(A \cap B)}{P(A)}$  
(단 $P(A) > 0$)  
표본공간이 변한다고 생각하면 된다.  
일어날 사건이 앞에 온다. **뒤에거 일때 앞에거** 이렇게 외우자  
<p>&nbsp;</p>  

**곱셈법칙**  
조건부확를을 안다면 A, B가 동시에 일어날 확률을 구할 수 있다.  

$P(B|A) = \dfrac{P(A \cap B)}{P(A)}$  
$\Rightarrow \ \ P(A \cap B) = P(B|A)P(A)$  
<p>&nbsp;</p>  

**독립 (Independent)**  
$P(B|A) = P(B)$ 인 경우 사건 A, B는 서로 독립이라고 한다.  
A사건과 B사건은 서로간 전혀 영향을 끼치지 않는 사건이라는 뜻이며 동시에 일어날 확률은 곱하면 얻을 수 있다.  
$P(A \cap B) = P(B|A)P(A) = P(B)P(A) = P(A)P(B)$  
<p>&nbsp;</p>  

**여사건**  
사건 $A$의 여사건: 사건 $A$가 일어나지 않을 사건 ($A^C$로 표시)    
$A$와 $A^C$중 둘중하나는 반드시 발생한다. (둘다 발생안하는 경우는 없다)
어떤 사건과 그 여사건은 서로 배반이다.  
$P(A \cup A^C) = P(A) + P(A^C) = 1$  
$P(A) = 1 - P(A^C)$  
<p>&nbsp;</p>  

**확률의 분할법칙**  
$B = (A \cap B) \cup (A^C \cap B)$  
$= P(A \cap B) + P(A^C \cap B)$ -> 두 항이 배반이므로  
$= P(B|A)P(A) + P(B|A^C)P(A^C)$ -> 곱셈법칙 적용  
=> 사건 B의 확률을 A가 일어났을 때 조건부 확률과 A가 일어나지 않았을때 조건부 확률로 나눠서 구할 수 있다.  
<p>&nbsp;</p>  


**베이즈 정리**  
어떤 사건의 사전확률과 사후확률의 관계를 나타낸 정리
$P(A|B) = \dfrac{P(A \cap B}{P(B)} = \dfrac{P(B|A)P(A)}{P(B)}$  

분할법칙을 적용하면 $=\dfrac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)}$  
=> 확률을 계산할 때 추가정보가 있으면 그 정보로 인해 $P(A)$가 $P(A|B)$로 변하는데 이 값을 구하는 정리  
- 사전확률: 처음의 확률 $P(A)$
- 사후확률: 수정된 확률 $P(A|B)$
- 일반화
$P(B_r|A) = \dfrac{P(B_r)P(A|B_r)}{\sum\limits_{i=1}^k P(B_i)P(A|B_I)}$ 
=> $P(A|B)$를 반대인 $P(B|A)$를 이용하여 구할 때 사용한다.  
<p>&nbsp;</p>  


## 확률변수 (Random Variable)  

랜덤한 실험 결과에 의존하는 실수 
=> 확률변수는 무조건 **실수**이다, 색깔, 모양 이런거는 확률변수가 아님  
 
즉 표본 공간의 부분집합에 대응하는 실수  
ex)  주사위를 던지는 실험에서 주사위 눈의 값  

보통 표본공간에서 실수로 대응되는 함수로 정의 X나 Y같은 대문자로 표시  

- 이산 확률 변수 (discrete random variable)
확률 변수가 취할 수 있는 모든 수 값들을 하나씩 셀 수 있는 경우  
ex) 주사위의 눈  

- 연속 확률 변수 (continuous random variable)  
셀 수 없는 경우  
ex) 학생들의 키  

### 확률 분포 
확률변수가 가질 수 있는 값에 대해 확률을 대응시켜주는 관계  

**확률분포의 표현: 매우다양함**  
표, 그래프, 함수, ...
<p>&nbsp;</p>  

**확률 변수 X도 평균과 분산을 가짐**  
실험 횟수에 따라 나온 X의 값들을 이용하면 평균과 분산을 구할 수 있다. 이 평균과 분산을 모집단의 평균과 분산이라고 할 수 있다.   
횟수가 많아질수록 더 정확해짐  
<p>&nbsp;</p>  

### 이산확률변수  

**이산확률변수의 확률분포**  
보통 함수로 주어진다.  
확률변수 X가 x라는 값을 가질 확률을 아래와 같이 표현한다.   
$P(X=x) = f(x)$  
<p>&nbsp;</p>  

**이산확률변수의 평균**  
기대값 (expected vlaue)이라고도 하며 아래와 같은 방법으로 구한다.  
$E(x) = \sum_x xP(X=x) = \sum_x xf(x)$  
<p>&nbsp;</p>  

**이산확률변수의 분산**  
이산확률변수의 분산은 $Var(X)$라고도 부르며 평균을 계산했다면 분산 또한 계산할 수 있다.  
이산확률변수에서 분산은 $(X-\mu)$의 평균으로 정의되며 아래와 같이 구한다.  
$\sigma^2 = E[(X-\mu)^2] = \sum_x(x-\mu)^2P(X=x) = \sum_x(x-\mu)^2f(x)$  

위의 값을 계산해보면 다른 방식으로도 분산을 구할 수 있다.
$\sigma^2 = E(X^2) - {E(X)}^2$  
=> 분산을 구하는 두 가지 방법 중 적합한 방법을 골라서 사용하면 된다.  

표준편차는 전과 마찬가지로 분산의 양의 제곱근으로 구하며 SD(X)라고도 부른다.  
<p>&nbsp;</p>  

**결합확률 분포 (joint probability distribution)**  
두 개 이상의 확률 변수가 동시에 취하는 값들에 대해 확률을 대응시켜주는 관계  
<p>&nbsp;</p>  

**주변확률분포 (marginal probability distribution)**  
결합확률분포를 통해 각 확률변수의 확률분포를 도출한 것  
각 변수에 대한 확률만 더해서 구한다.  
<p>&nbsp;</p>  

**공분산 (Covariance)**  
확률변수 $X$, $Y$의 공분산은 $(X- \mu_X)(Y - \mu_Y)$의 평균으로 정의되며 아래와 같이 구한다.  
$Cov(X, Y) = E[(X - \mu_X)(Y - \mu_Y)] = E(XY) - \mu_X\mu_Y = E[XY] - E[X][Y]$  
공분산을 이용해서 두 확률변수 $X$, $Y$의 상관관계를 알 수 있다.  
<p>&nbsp;</p>  

**상관계수 (Correlation coefficient)**  

공분산은 각 확률 변수의 절대적인 크기에 영향을 받는다.
단위에 의한 영향을 없일 필요가 있다.  
=> 단위에 의한 영향을 없앤 공분산  

$\rho = Corr(X, Y) = \dfrac{Cov(X,Y)}{\rho_X\rho_Y}$  

상관계수는 -1~1사이의 값을 가지며 양수면 두 확률변수는 양의 상관관계, 음수면 음의 상관관계를 가지며 크기가 클수록 연관성이 크다는 뜻이다. 
- 양의 상관관계: 같이커짐  
- 음의 상관관계: 하나가 커지면 하나가 작아짐  
<p>&nbsp;</p>  



## 확률분포 (Probability Distribution)
확률변수가 가질수 있는 값중에서 어떤 값이 될지의 분포  
무수히 많이 존재할 수 있지만 실제 현상의 확률분포는 몇가지 유명한 확률분포로 표현된다.  

### 이항분포 (binomial Distribution)  

**베르누이 시행**  
정확하게 2개의 결과만을 가지는 실험 (동전던지기)
보통 성공과 실패로 결과를 구분
성공의 확률: p

**이항분포**  
n번의 베르누이 시행에서 성공의 횟수를 이항확률변수라고 한다.  
이항분포: 이항확률변수의 확률분포
이항확률 변수 X의 확률분포  
$f(x)$
